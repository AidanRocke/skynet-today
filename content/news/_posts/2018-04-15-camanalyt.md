---
title: "Is AI brainwashing us all, or a useless moderator?"
excerpt: "Reviewing the many claims made as part of the Cambridge Analytica/Facebook scandal"
author: limor_gultchin
tags: [Facebook, data, priacy, AI, curating algorithms]
---
This past month’s Cambridge Analytica scandal triggered some important conversations regarding privacy and the current uses of AI in social platforms. It also offered another great example of how less than careful reporting can create a wide-reaching narrative about data heists and mind controlling AI. 

## What Happened
March 16 was the day this story first gained attention. In a seemingly [naive blog post](https://newsroom.fb.com/news/2018/03/suspending-cambridge-analytica/) in facebook’s ‘newsroom’ Paul Grewal, VP & Deputy General Counsel, announced that Cambridge Analytica is now suspended from Facebook. He also gave the first outline of the story from Facebook’s perspective: 
* Alexander Kogan, a researcher at Cambridge University, built an app called ‘yourdigitallife’ back in 2013
* Kogan passed facebook profile data of anyone who downloaded it to Cambridge Analytica against the terms and conditions he signed on with Facebook
* Facebook found this out in 2015, discontinued the app and asked for certification from all parties involved that the data was deleted. Recently, Facebook found out the data was not deleted in its entirety. 
So far so good.

What Facebook didn’t tell us in this blog post was that it was a preemptive strike meant to take some of the heat off of next day’s generous coverage of the story of Christopher Wylie, the ‘whistleblower’ of this data scandal, and one of Cambridge Analytica’s co-founders. The Guardian, the Observer and the New York Times all ran some variants of the story, with the Guardian’s piece being probably the most illustrious. While the NYT quoted Wylie as saying that he built for Cambridge Analytica [‘an “arsenal of weapons” in a culture war,’] (https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html#) the Guardian took a more personal angle - describing Wylie as ‘clever, funny, bitchy, profound, intellectually ravenous, compelling. A master storyteller.’, among other lofty compliments.

And yet, we managed to get some new facts from this round of publications:
* Kogan sold the data to Wylie and his colleagues. 
* Although 270,000 people downloaded his app, data of 50 Million people actually got to the hands of Cambridge Analytica, just by virtue of being friends with users who downloaded the app. 

We now know it was more like 87 Million (a fact that was once again strangely communicated by facebook at the end of a [rather vague blog post](https://newsroom.fb.com/news/2018/04/restricting-data-access/)).


## The Reactions
The real claim here was not only of a ‘data breach’, but more importantly that this spooky new thing called personal data was used for the creation of a psychological warfare, no less, and was a key factor in the results of Brexit and the 2016 American presidentials. It led some, like [François Chollet](https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704), to question and speculate about the nature of algorithmic driven social media platforms in their current form. Chollet’s main argument is that while we worry about AI robots taking over, reality is **already** more troubling: AI such as systems currently used by Facebook can influence and in fact brainwash users to the point of mind control. By curating which bits of information we get to see, and selecting information that will be personally influential to us (measured by how much we react to them, and with which sentiment) it can alter our world view. Social pressured, AI edition.

Another wave of reporting on the topic came at the heels of Mark Zuckerberg’s hearing at the American congress, which focused on the recent Cambridge Analytica scandal, as well as on earlier reports about Facebook’s involvement in the Russian elections meddling. Its hilarious side kept us up to date with the [incredible memes] (http://www.bbc.co.uk/news/newsbeat-43722444) it gave us; the more serious side questioned Zuckerberg’s repeated claims that AI will fix most issues he was questioned about. Most reports slammed Facebook for making that claim, explaining the [AI cannot be relied on] (https://www.washingtonpost.com/news/the-switch/wp/2018/04/11/ai-will-solve-facebooks-most-vexing-problems-mark-zuckerberg-says-just-dont-ask-when-or-how/?utm_term=.b5c1f785a17e), that it will [never solve facebook’s problems] (https://www.buzzfeed.com/daveyalba/mark-zuckerberg-artificial-intelligence-facebook-content-pro?utm_term=.fcEl5M1mA1#.hv2ZyJdRed) or that it was an excuse in an attempt to [buy more time and nothing more] (https://www.theverge.com/2018/4/13/17235042/facebook-mark-zuckerberg-ai-artificial-intelligence-excuse-congress-hearings). Sarah Jeong of the Verge claimed that placing hopes in the ‘AI will fix it’ mantra is not only running from responsibility, it will also be the basis of the next facebook hearing.

Oh, and of course, [#deletefacebook] (https://twitter.com/hashtag/deletefacebook?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Ehashtag).


## Our Perspective
The storm that has been rolling for just about a month now has many facets, But focusing on the AI angle, here are our main takeaways:
* AI isn’t mind controlling us just yet. By accepting Cambridge Analytica’s and Christopher Wiley’s narrative about the powerful psychological weapons we built we fall prey to their avidently effective PR. There is little evidence to the role their tools indeed played in the Brexit/Trump votes, and we have little scientific evidence on targeted ads online actually mind controlling anyone, as Chris Kavanagh excellently argued in his widely read [medium piece](https://medium.com/@CKava/why-almost-everything-reported-about-the-cambridge-analytica-facebook-hacking-controversy-is-db7f8af2d042). Cambridge Analytica’s weapon failed getting Ted Cruz elected in the very primaries race to the same elections. And was it really this infamous weapon that tipped the vote, much more than the FBI’s announcement regarding Clinton’s email probe just days before the election? Or the fundamental anti-establishment sentiments reeking in parts of US and Britain prior to the elections? Perhaps, but that sounds like a frail causal, reductionist claim. Besides, judging by most targeted ads currently (mostly based on logistic regression), it looks like we’re technically pretty far off:
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Dear Amazon, I bought a toilet seat because I needed one. Necessity, not desire. I do not collect them. I am not a toilet seat addict. No matter how temptingly you email me, I&#39;m not going to think, oh go on then, just one more toilet seat, I&#39;ll treat myself.</p>&mdash; Jac Rayner (@GirlFromBlupo) <a href="https://twitter.com/GirlFromBlupo/status/982156453396996096?ref_src=twsrc%5Etfw">April 6, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

* By pinning the problem on AI, or claiming that ‘AI will never solve the problem’, authors are making the same kind of sweeping arguments they pretend to be criticizing. No, AI will not save us **all** from **everything**. But AI is not a static one trick pony. These are by definition tools that get better over time and can be trained on different data with different objectives; we can and are becoming better at using them to address a wide variety of problems, explicitly in the field of classification and clustering of content, which is very much the nature of the moderation problem at hand. It will be an ever going battle between moderators and violators, just like a cop v. robber situation, but it does not mean we should discredit some of the most effective tools to carry it out. We can, however, spend much more resources in an effort to develop more transparent AI, and demand curating algorithms to give us back control over what they’re optimizing for, as [Franocis Chollet rightfully suggests] (https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704).  

* Much of the reaction to this story is emotional: we feel like we were betrayed by that friend we stalk our ex-s with, the one we ask for restaurant recommendations. Other platforms are not personal in the same way.

* Moreover, that data was not used for just any cause, but to theoretically help the making of the most anti-establishment votes we have seen in years. Pinning the success of the relatively extreme outcomes of the votes on tech is too easy of a solution, that allows us to not face the reality of a system that has stopped delivering for certain people. Similar tools at the hand of different political candidates didn’t alarm people so much but a few years ago. 

## TLDR
A breach of trust, not of technology, led to a scare about data accumulation, use for psychological warfare and claims about sinister/useless AI. The truth as always is somewhat more complicated. Tech giants should be much more transparent about future incidents and yes, employ AI as a tool in this battle, among other tools. They And the brain washing robots are not here quite yet.
