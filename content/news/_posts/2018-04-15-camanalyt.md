---
title: "Is Data-Driven AI Brainwashing us all, or is it Just the Same as Good ol' Marketing?"
excerpt: "The many claims made as part of the recent Cambridge Analytica/Facebook scandal, reviewed"
author: limor_gultchin
editor: andrey_kurenkov
tags: [Facebook, privacy, BigBiz]
---
This past month’s Cambridge Analytica scandal triggered some important conversations regarding privacy and the current uses of AI in social platforms. It is also another great example of how flawed reporting can create wide-reaching but inaccurate narratives about AI. 

## What Happened
This story started on March 16, with a seemingly naive blog post by Facebook’s VP & Deputy General Counsel Paul Grewal. The post announced that Cambridge Analytica is now suspended from Facebook and gave the first outline of the story from Facebook’s perspective: 
* Alexander Kogan, a researcher at Cambridge University, built an app called ‘yourdigitallife’ back in 2013
* Kogan passed facebook profile data of anyone who downloaded it to Cambridge Analytica, which violated Facebook’s terms and conditions
* Facebook found this out in 2015, discontinued the app and asked for certification from all parties involved that the data was deleted. 
* Recently, Facebook found out the data was not deleted in its entirety, and thus the suspension of Cambridge Analytica and blog post.  

So far so good.

What Facebook didn’t tell us was that the blog post was a pre-emptive measure to influece public perceptions before next day’s generous coverage of this story as told by Christopher Wylie, the whistleblower of this data scandal and one of Cambridge Analytica’s co-founders. [The Guardian](https://www.theguardian.com/news/2018/mar/17/data-war-whistleblower-christopher-wylie-faceook-nix-bannon-trump) and the [New York Times](https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html#) all ran some variants of the story, with the Guardian’s piece being probably the most notable. While the NYT quoted Wylie as saying that he built for Cambridge Analytica ‘an “arsenal of weapons” in a culture war,’ the Guardian took a more personal angle - describing Wylie as ‘clever, funny, bitchy, profound, intellectually ravenous, compelling. A master storyteller.’, among other lofty compliments.

And yet, we managed to get some new facts from this round of publications:
* Kogan sold the data to Wylie and his colleagues. 
* Although 270,000 people downloaded his app, data of 50 Million people actually got to the hands of Cambridge Analytica, just by virtue of being friends with users who downloaded the app. 

We now know it was more like 87 Million — a staggering quantity that would have been unthinkable before the internet age.


## The Reactions
The story soon evolved beyond the facts of the ‘data breach’ to be about how this spooky new thing called personal data was used for the creation of a psychological warfare. Psychological warfare, quite literally — unlike old-school marketing. The reports claimed it was a key factor in the results of Brexit and the 2016 American presidential election. 

It led some, like [François Chollet](https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704), to question and speculate about the nature of algorithmic driven social media platforms in their current form. Chollet’s main argument is that while we worry about AI robots taking over, reality is **already** more troubling: AI algorithms such as the ones already used by Facebook can influence and perhaps even 'brainwash' users virtually to the point of mind control. By curating which bits of information we get to see, and selecting information that will be personally influential to us (measured by how much we react to them, and with which sentiment) it can alter our world view. Social pressure, AI edition.

Another wave of reporting on the topic came at the heels of Mark Zuckerberg’s hearing at the American congress, which focused on the recent Cambridge Analytica scandal, as well as on earlier reports about Facebook’s involvement in the Russian election meddling. there were some less serious elements to the reporting, with [incredible memes] (http://www.bbc.co.uk/news/newsbeat-43722444) that were also informative. The more serious reporting questioned Zuckerberg’s repeated claims that AI will fix most issues he was questioned about. Most reports slammed Facebook for making that claim, explaining the [AI cannot be relied on] (https://www.washingtonpost.com/news/the-switch/wp/2018/04/11/ai-will-solve-facebooks-most-vexing-problems-mark-zuckerberg-says-just-dont-ask-when-or-how/), that it will [never solve facebook’s problems] (https://www.buzzfeed.com/daveyalba/mark-zuckerberg-artificial-intelligence-facebook-content-pro) or that the whole idea is an excuse in an attempt to [buy more time and nothing more] (https://www.theverge.com/2018/4/13/17235042/facebook-mark-zuckerberg-ai-artificial-intelligence-excuse-congress-hearings). Sarah Jeong of the Verge claimed that placing hopes in the ‘AI will fix it’ mantra is not only running from responsibility, it will also be the basis of the next Facebook hearing.

Oh, and of course, [#deletefacebook] (https://twitter.com/hashtag/deletefacebook).


## Our Perspective
The storm that has been rolling for just about a month now has many facets, but here are our main takeaways on just the AI aspects of it:

* AI isn’t mind controlling us just yet. By accepting Cambridge Analytica’s and Christopher Wiley’s narrative about the powerful psychological weapons they built we fall prey to their evidently effective PR. There is little evidence to the role their tools indeed played in the Brexit/Trump votes and we have little scientific evidence that targeted ads online can actually mind control anyone, as Chris Kavanagh excellently argued in his widely read [medium piece](https://medium.com/@CKava/why-almost-everything-reported-about-the-cambridge-analytica-facebook-hacking-controversy-is-db7f8af2d042). Was it really this infamous weapon that tipped the vote, much more than the FBI’s announcement regarding Clinton’s email probe just days before the election? Or the fundamental anti-establishment sentiments reeking in parts of US and Britain prior to the elections? Perhaps, but that sounds like a frail causal, reductionist claim. Besides, judging by most targeted ads currently (mostly based on logistic regression), it looks like we’re technically pretty far off:
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Dear Amazon, I bought a toilet seat because I needed one. Necessity, not desire. I do not collect them. I am not a toilet seat addict. No matter how temptingly you email me, I&#39;m not going to think, oh go on then, just one more toilet seat, I&#39;ll treat myself.</p>&mdash; Jac Rayner (@GirlFromBlupo) <a href="https://twitter.com/GirlFromBlupo/status/982156453396996096?ref_src=twsrc%5Etfw">April 6, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

* By pinning the problem on AI, or claiming that ‘AI will never solve the problem’, authors are making the same kind of sweeping arguments they pretend to be criticizing. No, AI will not save us **all** from **everything**. But AI is not a static one trick pony. These are by definition tools that get better over time and can be trained on different data with different objectives; we can and are becoming better at using them to address a wide variety of problems, including the moderation problem at hand. It will be an ever going battle between moderators and violators, just like a cop v. robber situation, but it does not mean we should discredit some of the most effective tools to carry it out. We can, however, spend much more resources in an effort to develop more transparent AI, and demand curating algorithms to give us back control over what they’re optimizing for, as [Francois Chollet rightfully suggests] (https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704).  

* Much of the reaction to this story is emotional: we feel like we were betrayed by that friend we stalk our ex-s with, the one we ask for restaurant recommendations. Other platforms are not personal in the same way. The combination of the nature of this platform, and the end to which its data was allegedly used - some of the most divided, controversial votes we have seen in years - makes us all react more vocally than usual.

Above all, a productive conversation should not focus on smearing the tools or the technology -- that's too easy and too simplistic. It should focus on the values we would like them to reflect.

## TLDR
A breach of trust, not of technology, led to a scare about data accumulation, use for psychological warfare and claims about sinister/useless AI. The truth as always is somewhat more complicated. Tech giants should be much more transparent about future incidents and yes, employ AI as a tool in this battle, among other tools. And the brain washing robots are not here quite yet.
